{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (32561, 15) -> (30162, 15)       delta: 7.37%\n",
      "Test data shape : (16281, 15) -> (15060, 15)       delta: 7.50%\n"
     ]
    }
   ],
   "source": [
    "columns = ['age', 'workclass', 'fnlwgt', 'education', 'educationNum', \n",
    "           'maritalStatus', 'occupation', 'relationship', 'race', 'sex',\n",
    "           'capitalGain', 'capitalLoss', 'hoursPerWeek', 'nativeCountry', 'income']\n",
    "continues_columns = ['age', 'fnlwgt', 'educationNum', 'capitalGain', 'capitalLoss', 'hoursPerWeek']\n",
    "discrete_columns = [_ for _ in columns if _ not in continues_columns]\n",
    "\n",
    "\n",
    "train_data = pd.read_csv('data/adult.data', delimiter=', ', header=None, engine='python')\n",
    "test_data = pd.read_csv('data/adult.test', delimiter=', ', header=None, skiprows=1, engine='python')\n",
    "train_data.columns = columns\n",
    "test_data.columns = columns\n",
    "\n",
    "\n",
    "# 离散数据：按列编码为float类型\n",
    "LE = LabelEncoder()\n",
    "for i in range(len(columns)):\n",
    "    if columns[i] in continues_columns: continue\n",
    "    train_data[columns[i]] = LE.fit_transform(train_data[columns[i]]).astype(float)\n",
    "    test_data[columns[i]] = LE.fit_transform(test_data[columns[i]]).astype(float)\n",
    "\n",
    "\n",
    "X_train = train_data.iloc[:, :-1]\n",
    "y_train = train_data.iloc[:, -1]\n",
    "X_test = test_data.iloc[:, :-1]\n",
    "y_test = test_data.iloc[:, -1]\n",
    "\n",
    "\n",
    "# 清洗数据：删除有缺失值的样本\n",
    "origin_train_shape = train_data.shape\n",
    "origin_test_shape = test_data.shape\n",
    "for column in columns:\n",
    "    train_data = train_data[~train_data[column].str.contains('\\?', regex=True)]\n",
    "    test_data = test_data[~test_data[column].str.contains('\\?', regex=True)]\n",
    "after_train_shape = train_data.shape\n",
    "after_test_shape = test_data.shape\n",
    "print(f\"Train data shape: {origin_train_shape} -> {after_train_shape} \\\n",
    "      delta: {(origin_train_shape[0] - after_train_shape[0]) / origin_train_shape[0] * 100:.2f}%\")\n",
    "print(f\"Test data shape : {origin_test_shape} -> {after_test_shape} \\\n",
    "      delta: {(origin_test_shape[0] - after_test_shape[0]) / origin_test_shape[0] * 100:.2f}%\")\n",
    "\n",
    "\n",
    "# 连续型数据离散化\n",
    "continues_columns = ['age', 'fnlwgt', 'educationNum', 'capitalGain', 'capitalLoss', 'hoursPerWeek']\n",
    "for column in continues_columns:\n",
    "    train_data[column] = pd.qcut(train_data[column].astype(float), 10, duplicates='drop')\n",
    "    test_data[column] = pd.qcut(test_data[column].astype(float), 10, duplicates='drop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode:\n",
    "    def __init__(self, dataset, left, right, feature_name, feature_value, label):\n",
    "        self.dataset = dataset\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.feature_name = feature_name\n",
    "        self.feature_value = feature_value\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gini(df):\n",
    "    \"\"\"\n",
    "    计算数据集的基尼指数\n",
    "    :param df: 数据集\n",
    "    :return: 基尼指数\n",
    "    \"\"\"\n",
    "    \n",
    "    val_list = pd.unique(df)\n",
    "    gini = 1\n",
    "    df = np.array(df)\n",
    "    for val in val_list:\n",
    "        p = df[df == val].size / df.size\n",
    "        gini -= p**2\n",
    "    return gini\n",
    "\n",
    "\n",
    "def split_dataset(df, index, value):\n",
    "    \"\"\"\n",
    "    按照给定的列划分数据集\n",
    "    :param df: 原始数据集\n",
    "    :param index: 指定特征的列索引，即feature\n",
    "    :param value: 指定特征的值\n",
    "    :return: 切分后的数据集\n",
    "    \"\"\"\n",
    "\n",
    "    # 划分数据集\n",
    "    left = df[df[index] == value]\n",
    "    right = df[df[index] != value]\n",
    "\n",
    "    # 删除划分后的数据集中的特征列\n",
    "    left = left.drop(index, axis=1)\n",
    "    right = right.drop(index, axis=1)\n",
    "\n",
    "    return left, right\n",
    "\n",
    "\n",
    "def choose_best_feature_to_split(df, flags):\n",
    "    \"\"\"\n",
    "    选择最好的特征进行分裂\n",
    "    :param df: 数据集\n",
    "    :return: best_value:(分裂特征的index, 特征的值), best_df:(分裂后的左右子树数据集), best_gain:(选择该属性分裂的最大信息增益), best_feature_value:(分裂特征的值)\n",
    "    \"\"\"\n",
    "\n",
    "    best_feature = None\n",
    "    best_split_value = None\n",
    "    best_gain = 0\n",
    "    best_feature_value = None\n",
    "\n",
    "    base_gini_index = calc_gini(df[\"income\"])\n",
    "\n",
    "    for feature in df.columns:\n",
    "        if flags[columns.index(feature)] == 1:\n",
    "            continue\n",
    "\n",
    "        for value in df[feature].unique():\n",
    "            left_df, right_df = split_dataset(df, feature, value)\n",
    "            gini_index = calc_gini(\n",
    "                left_df[:][\"income\"]) + calc_gini(right_df[:][\"income\"])\n",
    "            gain = gini_index - base_gini_index\n",
    "            if gain > best_gain:\n",
    "                best_feature = feature\n",
    "                best_split_value = (left_df, right_df)\n",
    "                best_gain = gain\n",
    "                best_feature_value = value\n",
    "\n",
    "    return best_feature, best_split_value, best_gain, best_feature_value\n",
    "\n",
    "\n",
    "def build_decision_tree(df, columns, flags):\n",
    "    \"\"\"\n",
    "    构建CART树\n",
    "    :param df: 数据集\n",
    "    :param columns: 特征列表\n",
    "    :param flags: 区分特征是否被完全区分开,初始为全0, 若某个特征被区分开那么flags对应的下标为0\n",
    "    :return: CART树\n",
    "    \"\"\"\n",
    "\n",
    "    # 递归结束情况1: 若当前集合的所有样本标签相等,即样本已被分\"纯\",则可以返回该标签值作为一个叶子节点\n",
    "    # 递归结束情况2: 若当前训练集的所有特征都被使用完毕,当前无可用特征但样本仍未分\"纯\"，则返回样本最多的标签作为结果\n",
    "    flags[columns.index('income')] = 1\n",
    "    if df.shape[0] == 0:\n",
    "        return TreeNode(df, None, None, 'income', None, -1)\n",
    "    if (len(df['income'].unique()) == 1) or (sum(flags) == len(columns)):\n",
    "        return TreeNode(df, None, None, 'income', None, df['income'].value_counts().keys()[0])\n",
    "\n",
    "    best_feature, best_split_value, best_gain, best_feature_value = choose_best_feature_to_split(\n",
    "        df, flags)\n",
    "    if best_gain > 0:\n",
    "        flags[columns.index(best_feature)] = 1\n",
    "        left = build_decision_tree(best_split_value[0], columns, flags)\n",
    "        right = build_decision_tree(best_split_value[1], columns, flags)\n",
    "        return TreeNode(df, left, right, best_feature, best_feature_value, None)\n",
    "    else:\n",
    "        return TreeNode(df, None, None, 'income', None, df['income'].value_counts().keys()[0])\n",
    "\n",
    "\n",
    "def save_decision_tree(cart):\n",
    "    \"\"\"\n",
    "    决策树的存储\n",
    "    :param cart: 训练好的决策树\n",
    "    :return: void\n",
    "    \"\"\"\n",
    "\n",
    "    np.save('cart.npy', cart)\n",
    "\n",
    "\n",
    "def load_decision_tree():\n",
    "    \"\"\"\n",
    "    决策树的加载\n",
    "    :return: 保存的决策树\n",
    "    \"\"\"\n",
    "\n",
    "    cart = np.load('cart.npy', allow_pickle=True)\n",
    "    return cart.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_copy = train_data.copy()\n",
    "flags = [0 for _ in range(len(columns))]\n",
    "cart = build_decision_tree(train_data_copy, columns, flags)\n",
    "save_decision_tree(cart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.x 使用 sk-learn 包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率：0.81\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "columns = ['age', 'workclass', 'fnlwgt', 'education', 'educationNum', \n",
    "           'maritalStatus', 'occupation', 'relationship', 'race', 'sex',\n",
    "           'capitalGain', 'capitalLoss', 'hoursPerWeek', 'nativeCountry', 'income']\n",
    "continues_columns = ['age', 'fnlwgt', 'educationNum', 'capitalGain', 'capitalLoss', 'hoursPerWeek']\n",
    "discrete_columns = [_ for _ in columns if _ not in continues_columns]\n",
    "\n",
    "\n",
    "train_data = pd.read_csv('data/adult.data', delimiter=', ', header=None, engine='python')\n",
    "test_data = pd.read_csv('data/adult.test', delimiter=', ', header=None, skiprows=1, engine='python')\n",
    "train_data.columns = columns\n",
    "test_data.columns = columns\n",
    "\n",
    "\n",
    "# 离散数据：按列编码为float类型\n",
    "LE = LabelEncoder()\n",
    "for i in range(len(columns)):\n",
    "    if columns[i] in continues_columns: continue\n",
    "    train_data[columns[i]] = LE.fit_transform(train_data[columns[i]]).astype(float)\n",
    "    test_data[columns[i]] = LE.fit_transform(test_data[columns[i]]).astype(float)\n",
    "\n",
    "\n",
    "X_train = train_data.iloc[:, :-1]\n",
    "y_train = train_data.iloc[:, -1]\n",
    "X_test = test_data.iloc[:, :-1]\n",
    "y_test = test_data.iloc[:, -1]\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'准确率：{accuracy:.2f}')\n",
    "\n",
    "# tree.plot_tree(clf, filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(cart, df_row, columns):\n",
    "    \"\"\"\n",
    "    用训练好的决策树进行分类\n",
    "    :param cart:决策树模型\n",
    "    :param df_row: 一条测试样本\n",
    "    :param columns: 特征列表\n",
    "    :return: 预测结果\n",
    "    \"\"\"\n",
    "\n",
    "    if cart.label != None:\n",
    "        return cart.label\n",
    "\n",
    "    else:\n",
    "        if df_row[columns.index(cart.feature_name)] == cart.feature_value:\n",
    "            return classify(cart.left, df_row, columns)\n",
    "        else:\n",
    "            return classify(cart.right, df_row, columns)\n",
    "\n",
    "\n",
    "def predict(cart, df, columns):\n",
    "    \"\"\"\n",
    "    用训练好的决策树进行分类\n",
    "    :param cart:决策树模型\n",
    "    :param df: 所有测试集\n",
    "    :param columns: 特征列表\n",
    "    :return: 预测结果\n",
    "    \"\"\"\n",
    "\n",
    "    pred_list = []\n",
    "    for i in range(len(df)):\n",
    "        pred_label = classify(cart, df.iloc[i, :], columns)\n",
    "        if pred_label == -1:\n",
    "            pred_label = random.randint(0, 1)  # 防止classify执行到返回-1,但一般不会执行到返回-1\n",
    "        pred_list.append(pred_label)\n",
    "    return pred_list\n",
    "\n",
    "\n",
    "def calc_acc(pred_list, test_list):\n",
    "    \"\"\"\n",
    "    返回预测准确率\n",
    "    :param pred_list: 预测列表\n",
    "    :param test_list: 测试列表\n",
    "    :return: 准确率\n",
    "    \"\"\"\n",
    "\n",
    "    pred = np.array(pred_list)\n",
    "    test = np.array(test_list)\n",
    "    acc = np.sum(pred == test) / len(test_list)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.7510775147536636\n",
      "Test accuracy :  0.50199203187251\n"
     ]
    }
   ],
   "source": [
    "cart = load_decision_tree()\n",
    "\n",
    "pred_train_list = predict(cart, train_data, columns)\n",
    "train_list = train_data['income'].to_numpy()\n",
    "acc_train = calc_acc(pred_train_list, train_list)\n",
    "print(\"Train accuracy: \", acc_train)\n",
    "\n",
    "pred_test_list = predict(cart, test_data, columns)\n",
    "test_list = [0 if i == '<=50K' else 1 for i in test_data['income'].to_numpy()]\n",
    "acc_test = calc_acc(pred_test_list, test_list)\n",
    "print(\"Test accuracy : \", acc_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
