{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64 object int64 object int64 object object object object object int64 int64 int64 object object \n",
      "清洗前的数据规模：训练集 -> (32561, 15) 测试集 -> (16281, 15)\n",
      "清洗后的数据规模：训练集 -> (30162, 15) 测试集 -> (15060, 15)\n",
      "int64 object int64 object int64 object object object object object int64 int64 int64 object object \n",
      "int64 float64 int64 float64 int64 float64 float64 float64 float64 float64 int64 int64 int64 float64 float64 \n",
      "category float64 category float64 category float64 float64 float64 float64 float64 category category category float64 float64 \n",
      "    age  workclass       fnlwgt  education educationNum  maritalStatus  \\\n",
      "0  37.0        5.0   60014.5995        9.0      11.5000            4.0   \n",
      "1  45.5        4.0   60014.5995        9.0      11.5000            2.0   \n",
      "2  37.0        2.0  228330.2000       11.0       4.9995            0.0   \n",
      "3  70.0        2.0  228330.2000        1.0       4.9995            2.0   \n",
      "4  29.5        2.0  872511.1000        9.0      11.5000            2.0   \n",
      "\n",
      "   occupation  relationship  race  sex capitalGain capitalLoss hoursPerWeek  \\\n",
      "0         0.0           1.0   4.0  1.0  49999.4995   2177.9995      38.0000   \n",
      "1         3.0           0.0   4.0  1.0  49999.4995   2177.9995      18.4995   \n",
      "2         5.0           1.0   4.0  1.0  49999.4995   2177.9995      38.0000   \n",
      "3         5.0           0.0   2.0  1.0  49999.4995   2177.9995      38.0000   \n",
      "4         9.0           5.0   2.0  0.0  49999.4995   2177.9995      38.0000   \n",
      "\n",
      "   nativeCountry  income  \n",
      "0           38.0     0.0  \n",
      "1           38.0     0.0  \n",
      "2           38.0     0.0  \n",
      "3           38.0     0.0  \n",
      "4            4.0     0.0  \n"
     ]
    }
   ],
   "source": [
    "columns = ['age', 'workclass', 'fnlwgt', 'education', 'educationNum', \n",
    "           'maritalStatus', 'occupation', 'relationship', 'race', 'sex',\n",
    "           'capitalGain', 'capitalLoss', 'hoursPerWeek', 'nativeCountry', 'income']\n",
    "continues_columns = ['age', 'fnlwgt', 'educationNum', 'capitalGain', 'capitalLoss', 'hoursPerWeek']\n",
    "discrete_columns = [_ for _ in columns if _ not in continues_columns]\n",
    "\n",
    "\n",
    "# 读取数据\n",
    "train_data = pd.read_csv('data/adult.data', delimiter=', ', header=None, engine='python')\n",
    "test_data = pd.read_csv('data/adult.test', delimiter=', ', header=None, skiprows=1, engine='python')\n",
    "train_data.columns = columns\n",
    "test_data.columns = columns\n",
    "\n",
    "\n",
    "for col in columns: print(train_data[col].dtype, end=' ')\n",
    "print()\n",
    "\n",
    "\n",
    "# 清洗数据：删除含有缺失值的样本\n",
    "print(f\"清洗前的数据规模：训练集 -> {train_data.shape} 测试集 -> {test_data.shape}\")\n",
    "for column in columns:\n",
    "    train_data = train_data[~train_data[column].astype(str).str.contains('\\?')]\n",
    "    test_data = test_data[~test_data[column].astype(str).str.contains('\\?')]\n",
    "print(f\"清洗后的数据规模：训练集 -> {train_data.shape} 测试集 -> {test_data.shape}\")\n",
    "\n",
    "\n",
    "for col in columns: print(train_data[col].dtype, end=' ')\n",
    "print()\n",
    "\n",
    "\n",
    "# 离散数据：按列编码为float类型\n",
    "LE = LabelEncoder()\n",
    "for i in range(len(columns)):\n",
    "    if columns[i] in continues_columns: continue\n",
    "    train_data[columns[i]] = LE.fit_transform(train_data[columns[i]]).astype(float)\n",
    "    test_data[columns[i]] = LE.fit_transform(test_data[columns[i]]).astype(float)\n",
    "\n",
    "\n",
    "for col in columns: print(train_data[col].dtype, end=' ')\n",
    "print()\n",
    "\n",
    "\n",
    "# 连续数据：离散化为分位数区间的中值\n",
    "for column in continues_columns:\n",
    "    train_qcut = pd.qcut(train_data[column].astype(float), 5, duplicates='drop')\n",
    "    train_data[column] = train_qcut.apply(lambda x: x.mid)\n",
    "    test_qcut = pd.qcut(test_data[column].astype(float), 5, duplicates='drop')\n",
    "    test_data[column] = test_qcut.apply(lambda x: x.mid)\n",
    "\n",
    "\n",
    "for col in columns: print(train_data[col].dtype, end=' ')\n",
    "print()\n",
    "\n",
    "\n",
    "print(train_data.head())\n",
    "\n",
    "\n",
    "# 划分数据集\n",
    "X_train = train_data.iloc[:, :-1]\n",
    "y_train = train_data.iloc[:, -1]\n",
    "X_test = test_data.iloc[:, :-1]\n",
    "y_test = test_data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、自定义决策树模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, attribute=None, children=None, label=None):\n",
    "        self.attribute = attribute  # 当前结点属性\n",
    "        self.children = children    # 子节点字典，value: Node\n",
    "        self.label = label          # 叶结点标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier:\n",
    "    def __init__(self, criterion='entropy'):\n",
    "        self.criterion = criterion\n",
    "        self.tree = None\n",
    "\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.tree = self._build_tree(X_train, y_train)\n",
    "\n",
    "\n",
    "    def _build_tree(self, X: pd.DataFrame, y: pd.Series):\n",
    "        # 如果数据集为空，返回 None\n",
    "        if len(y) == 0:\n",
    "            return None\n",
    "\n",
    "        # 如果标签相同，返回叶子结点\n",
    "        if len(set(y)) == 1:\n",
    "            return Node(label=y.iloc[0])\n",
    "\n",
    "        # 选择最佳划分属性\n",
    "        best_attribute, best_gain = self._choose_best_attribute(X, y)\n",
    "\n",
    "        # 如果没有合适的划分，返回叶子结点\n",
    "        if best_gain == 0:\n",
    "            return Node(label=Counter(y).most_common(1)[0][0])\n",
    "\n",
    "        # 构建叶子结点\n",
    "        children = {}\n",
    "        for value in X[best_attribute].unique():\n",
    "            # 根据属性值划分数据集\n",
    "            value_indices = (X[best_attribute] == value)\n",
    "            X_subset = X.loc[value_indices]\n",
    "            y_subset = y.loc[value_indices]\n",
    "\n",
    "            # 递归构建叶子结点\n",
    "            child_node = self._build_tree(X_subset, y_subset)\n",
    "            children[value] = child_node\n",
    "\n",
    "        # 返回内叶子结点\n",
    "        return Node(attribute=best_attribute, children=children)\n",
    "\n",
    "\n",
    "    def _choose_best_attribute(self, X, y):\n",
    "        best_gain = 0\n",
    "        best_attribute = None\n",
    "\n",
    "        # 遍历所有特征\n",
    "        for attribute in X.columns:\n",
    "            # 获取当前特征的唯一值\n",
    "            values = X[attribute].unique()\n",
    "\n",
    "            # 划分数据集\n",
    "            subsets = defaultdict(list)\n",
    "            for value in values:\n",
    "                indices = (X[attribute] == value)\n",
    "                y_subset = y.loc[indices]\n",
    "                subsets[value] = y_subset\n",
    "\n",
    "            gain = self._calculate_gain(y, subsets)\n",
    "\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_attribute = attribute\n",
    "\n",
    "        return best_attribute, best_gain\n",
    "\n",
    "\n",
    "    def _calculate_gain(self, y, subsets):\n",
    "        # 根据选择的标准计算增益\n",
    "        if self.criterion == 'entropy':\n",
    "            gain = self._entropy_gain(y, subsets)\n",
    "        elif self.criterion == 'log_loss':\n",
    "            gain = self._ratio_gain(y, subsets)\n",
    "        elif self.criterion == 'gini':\n",
    "            gain = self._gini_gain(y, subsets)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported criterion\")\n",
    "        return gain\n",
    "\n",
    "\n",
    "    def _calculate_entropy(self, y: pd.Series) -> float:\n",
    "        counts = Counter(y)\n",
    "        total = len(y)\n",
    "        entropy = 0\n",
    "\n",
    "        for count in counts.values():\n",
    "            prob = count / total\n",
    "            entropy -= prob * np.log2(prob)\n",
    "\n",
    "        return entropy\n",
    "\n",
    "\n",
    "    def _entropy_gain(self, y: pd.Series, subsets: dict) -> float:\n",
    "        entropy = self._calculate_entropy(y)\n",
    "        child_entropy = np.sum([len(subset) / len(y) * self._calculate_entropy(subset) for subset in subsets.values()])        \n",
    "        return entropy - child_entropy\n",
    "\n",
    "\n",
    "    def _ratio_gain(self, y: pd.Series, subsets: dict) -> float:\n",
    "        gain = self._entropy_gain(y, subsets)\n",
    "        iv = np.sum([-len(subset) / len(y) * np.log2(len(subset) / len(y)) for subset in subsets.values()])\n",
    "        return 0 if iv == 0 else gain / iv\n",
    "    \n",
    "\n",
    "    def _gini_gain(self, y: pd.Series, subsets: dict) -> float:\n",
    "        gini_index = 0\n",
    "        for subset in subsets.values():\n",
    "            gini_index += len(subset) / len(y) * (1 - np.sum([(len(subset.loc[subset == label]) / len(subset)) ** 2 for label in subset.unique()]))\n",
    "        return -gini_index\n",
    "\n",
    "\n",
    "    def predict(self, X_test) -> np.array:\n",
    "        y_pred = [self._predict_single_sample(sample) for _, sample in X_test.iterrows()]\n",
    "        return np.array(y_pred)\n",
    "\n",
    "\n",
    "    def _predict_single_sample(self, sample):\n",
    "        node = self.tree\n",
    "        while node.label is None:\n",
    "            value = sample[node.attribute]\n",
    "\n",
    "            # 如果叶子结点为空，返回子结点中最多的标签\n",
    "            if value not in node.children or node.children[value] is None:\n",
    "                child_labels = []\n",
    "\n",
    "                # 仅当子节点存在且是叶节点时，获取其标签\n",
    "                for child_node in node.children.values():\n",
    "                    if child_node is not None and child_node.label is not None:\n",
    "                        child_labels.append(child_node.label)\n",
    "                \n",
    "                if len(child_labels) == 0: return 0.0\n",
    "                most_common_label = Counter(child_labels).most_common(1)[0][0]\n",
    "                return most_common_label\n",
    "\n",
    "            else:\n",
    "                node = node.children[value]\n",
    "\n",
    "        return node.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、多模型对照测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 使用 entropy 作为划分标准"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标准包准确率：0.78\n",
      "自实现准确率：0.77\n"
     ]
    }
   ],
   "source": [
    "clf_std = DecisionTreeClassifier(criterion='entropy')\n",
    "clf_std.fit(X_train, y_train)\n",
    "y_pred_std = clf_std.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_std)\n",
    "print(f'标准包准确率：{accuracy:.2f}')\n",
    "\n",
    "clf_my = MyDecisionTreeClassifier(criterion='entropy')\n",
    "clf_my.fit(X_train, y_train)\n",
    "y_pred_my = clf_my.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_my)\n",
    "print(f'自实现准确率：{accuracy:.2f}')\n",
    "\n",
    "# tree.plot_tree(clf_std, filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 使用 log_loss 作为划分标准"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标准包准确率：0.78\n",
      "自实现准确率：0.78\n"
     ]
    }
   ],
   "source": [
    "clf_std = DecisionTreeClassifier(criterion='log_loss')\n",
    "clf_std.fit(X_train, y_train)\n",
    "y_pred_std = clf_std.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_std)\n",
    "print(f'标准包准确率：{accuracy:.2f}')\n",
    "\n",
    "\n",
    "clf_my = MyDecisionTreeClassifier(criterion='log_loss')\n",
    "clf_my.fit(X_train, y_train)\n",
    "y_pred_my = clf_my.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_my)\n",
    "print(f'自实现准确率：{accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 使用 gini 作为划分标准"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标准包准确率：0.78\n",
      "自实现准确率：0.75\n"
     ]
    }
   ],
   "source": [
    "clf_std = DecisionTreeClassifier(criterion='gini')\n",
    "clf_std.fit(X_train, y_train)\n",
    "y_pred_std = clf_std.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_std)\n",
    "print(f'标准包准确率：{accuracy:.2f}')\n",
    "\n",
    "\n",
    "clf_my = MyDecisionTreeClassifier(criterion='gini')\n",
    "clf_my.fit(X_train, y_train)\n",
    "y_pred_my = clf_my.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_my)\n",
    "print(f'自实现准确率：{accuracy:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
